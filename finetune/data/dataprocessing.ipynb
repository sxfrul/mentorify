{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as conversational_dataset_nested.parquet!\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "# Define the conversational data with nested structure\n",
    "conversations = [\n",
    "    [\n",
    "        {\"from\": \"human\", \"value\": \"What is 2+2?\"},\n",
    "        {\"from\": \"gpt\", \"value\": \"Quizzable\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"from\": \"human\", \"value\": \"Explain why the sky is blue.\"},\n",
    "        {\"from\": \"gpt\", \"value\": \"Quizzable\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"from\": \"human\", \"value\": \"What is the capital of France?\"},\n",
    "        {\"from\": \"gpt\", \"value\": \"Quizzable\"}\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Define the schema with a nested list of structs for 'conversations'\n",
    "schema = pa.schema([\n",
    "    (\"conversations\", pa.list_(\n",
    "        pa.struct([\n",
    "            pa.field(\"from\", pa.string()),\n",
    "            pa.field(\"value\", pa.string())\n",
    "        ])\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Create a DataFrame (for easier conversion)\n",
    "df = pd.DataFrame({\"conversations\": conversations})\n",
    "\n",
    "# Convert the DataFrame to a PyArrow Table with the defined schema\n",
    "table = pa.Table.from_pandas(df, schema=schema)\n",
    "\n",
    "# Save the dataset as a Parquet file\n",
    "pq.write_table(table, \"conversational_dataset_nested.parquet\")\n",
    "\n",
    "print(\"Dataset saved as conversational_dataset_nested.parquet!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the conversation entry loop.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "# Define the schema with a nested list of structs for 'conversations'\n",
    "schema = pa.schema([\n",
    "    (\"conversations\", pa.list_(\n",
    "        pa.struct([\n",
    "            pa.field(\"from\", pa.string()),\n",
    "            pa.field(\"value\", pa.string())\n",
    "        ])\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Function to prompt for user input and GPT output\n",
    "def get_conversation_entry():\n",
    "    # Ask for user input and GPT output\n",
    "    user_input = input(\"Human: \")\n",
    "    gpt_output = input(\"GPT: \")\n",
    "\n",
    "    # Check if \"exit\" is entered in either field to break the loop\n",
    "    if user_input.lower() == \"exit\" or gpt_output.lower() == \"exit\":\n",
    "        return None  # Return None to indicate the loop should exit\n",
    "    \n",
    "    # Store the conversation as a list of dicts\n",
    "    conversation = [\n",
    "        {\"from\": \"human\", \"value\": user_input},\n",
    "        {\"from\": \"gpt\", \"value\": gpt_output}\n",
    "    ]\n",
    "    \n",
    "    return conversation\n",
    "\n",
    "# Function to append data to the Parquet file\n",
    "def append_to_parquet(new_conversation):\n",
    "    # Read the existing Parquet file into a PyArrow Table\n",
    "    try:\n",
    "        existing_table = pq.read_table(\"conversational_dataset_nested.parquet\")\n",
    "    except:\n",
    "        # If the file doesn't exist, create an empty table\n",
    "        existing_table = pa.Table.from_pandas(pd.DataFrame({\"conversations\": []}), schema=schema)\n",
    "    \n",
    "    # Convert new data into the same format\n",
    "    new_df = pd.DataFrame({\"conversations\": [new_conversation]})\n",
    "    \n",
    "    # Convert new DataFrame to PyArrow Table with the same schema\n",
    "    new_table = pa.Table.from_pandas(new_df, schema=existing_table.schema)\n",
    "    \n",
    "    # Concatenate the existing table with the new table (append)\n",
    "    combined_table = pa.concat_tables([existing_table, new_table])\n",
    "    \n",
    "    # Save the updated dataset back to the Parquet file\n",
    "    pq.write_table(combined_table, \"conversational_dataset_nested.parquet\")\n",
    "\n",
    "# Main loop to repeatedly ask for input and append to Parquet\n",
    "while True:\n",
    "    # Get a conversation entry\n",
    "    conversation = get_conversation_entry()\n",
    "    \n",
    "    if conversation is None:\n",
    "        print(\"Exiting the conversation entry loop.\")\n",
    "        break  # Exit the loop if \"exit\" was entered in either field\n",
    "    \n",
    "    # Append the new conversation to the Parquet file\n",
    "    append_to_parquet(conversation)\n",
    "    \n",
    "    # Ask if the user wants to add another conversation\n",
    "    continue_input = input(\"Do you want to add another conversation? (y/n): \")\n",
    "    if continue_input.lower() != 'y':\n",
    "        print(\"Exiting the conversation entry loop.\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
